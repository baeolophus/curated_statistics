[["index.html", "Statistics for Scared People Who is this book for?", " Statistics for Scared People C.M. Curry 2025-02-03 Who is this book for? "],["what-is-your-goal.html", "Chapter 1 What is your goal? 1.1 Exploratory or hypothesis generation 1.2 Inferential or hypothesis testing “Are things different” 1.3 Physical or mechanistic predictions - you can only statistics them away sometimes", " Chapter 1 What is your goal? 1.1 Exploratory or hypothesis generation 1.2 Inferential or hypothesis testing “Are things different” This is a hypothesis, not a description. Description can highlight, but doesn’t test what’s different. Descriptions can still have a bias (mean vs median vs range all show different things descriptively, PCA problems). Doesn’t mean it’s an experiment. summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 1.3 Physical or mechanistic predictions - you can only statistics them away sometimes You can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot. "],["types-of-resources.html", "Chapter 2 Types of resources", " Chapter 2 Types of resources Peer-reviewed vs not: what can you cite? What helps? "],["references.html", "References", " References "],["distributions.html", "Chapter 3 Distributions 3.1 Bounded 3.2 Heteroscedascitity vs homoscedasicity 3.3 Theoretical, existing, known 3.4 Simulated, randomized, computational 3.5 When to use either?", " Chapter 3 Distributions The underlying distribution of the variables in your sample population makes a big difference in what inferential statistics you can use. Different methods assume (or don’t) different distributions. If you violate assumptions, sometimes the statistical tests or estimates from the methods may not be valid. 3.1 Bounded 3.2 Heteroscedascitity vs homoscedasicity 3.3 Theoretical, existing, known 3.4 Simulated, randomized, computational 3.5 When to use either? It seems like objections to bootstrapping linear models (and presumably other complex models) fall into two categories: 1. Sampling design isn’t accounted for by complete randomization (ignoring stratification of categories or other sampling vagaries) 2. It’s less elegant (???). Venables and Ripley 2002, pg 164, say “we see bootstrapping as having little place in least-squares regression. If the errors are close to normal, the standard theory suffices. If not, there are better methods of fitting than least squares, or perhaps the data should be transformed […]” Hastie et al. 2008 (Elements of Statistical Learning) seem in favor of bootstrapping (johnston_bootstrap_2021?) are enthusiastically in favor of the bootstrap at least for their relatively simple design to replace a t-test. - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8613103/#CR47 – says do all the other stuff like deal with random effects and autocorrelation first. We have done this already. Example: should we run a Redundancy Analysis (RDA) a la https://r.qcbs.ca/workshop10/book-en/redundancy-analysis.html , which I understand has multivariate normality assumptions. He has a small sample size (around 35 I believe) and residuals are not coming out normal in smaller linear models. - https://journals.sagepub.com/doi/10.1177/0049124189018002003 - https://statisticsbyjim.com/hypothesis-testing/bootstrapping/ - https://online.stat.psu.edu/stat555/node/119/ - https://www.sagepub.com/sites/default/files/upm-binaries/21122_Chapter_21.pdf - https://link.springer.com/referenceworkentry/10.1007/978-1-4419-1153-7_84 "],["how-to-use-this-section.html", "How to use this section", " How to use this section Each section will contain some potential descriptions if needed OR direct citations and links to relevant literature if those explanations are clearest. "],["principal-components-analysis.html", "Principal components analysis 3.6 Explanation. 3.7 email text", " Principal components analysis 3.6 Explanation. Cite Allison Horst’s whale figure here. 3.6.1 Questions and data types 3.6.2 Key assumptions 3.6.3 Key distinctions among methods within PCA 3.7 email text 3.7.1 CART/ctree explanations - Start with this one, CART section mainly: [http://www.jstor.org/stable/10.1086/587826](http://www.jstor.org/stable/10.1086/587826) - [https://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees](https://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees) - [https://stats.stackexchange.com/questions/255150/how-to-interpret-this-decision-tree](https://stats.stackexchange.com/questions/255150/how-to-interpret-this-decision-tree) 3.7.2 Examples of PCA in the wild: - [https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/1051-0761%282006%29016%5B0687%3AHELMAR%5D2.0.CO%3B2](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/1051-0761%282006%29016%5B0687%3AHELMAR%5D2.0.CO%3B2) - Uses R’s ctree: [https://link.springer.com/article/10.1007/s11252-019-00896-0](https://link.springer.com/article/10.1007/s11252-019-00896-0) 3.7.3 Once you have decided to use it, check implementation "],["intraclass-correlation-coefficient-a.k.a.-repeatability.html", "Intraclass Correlation Coefficient a.k.a. repeatability 3.8 Explanation 3.9 Examples “in the wild”", " Intraclass Correlation Coefficient a.k.a. repeatability 3.8 Explanation 3.8.1 The basics A simple explanation and hopefully figure of what the test does or gets at. 3.8.2 More technical 3.8.2.1 Questions and data types Example problem structures and types of data you need. 3.8.2.2 Key assumptions and limitations This is how to know if you can use the method. Limitations are study design though Thresholds listed on the wikipedia page, but neither provides justifications for their thresholds. 3.8.2.3 Key distinctions among related methods “Generalizability theory” (“G-Theory”) is related to “classic test theory” which appears to contain repeatability and ICCs (Vispoel, Morris, and Kilinc 2018).This seems to provide a broader range of indices of how reliable measurements are, but may not be necessary for simple applications. 3.8.2.4 Implementation and controversies (Liljequist, Elfving, and Skavberg Roaldsen 2019) claim it doesn’t matter which ICC method you use, and that if you use all three main methods you can use any differences to suggest what type of bias you may have in measurements. (Curry 2016) describe how to implement in R and SAS. 3.8.3 Most technical The key citations. 3.9 Examples “in the wild” Citations and what is useful in the paper. The most updated guideline is (Ten Hove, Jorgensen, and Van Der Ark 2024) References Curry, Claire M. 2016. “Repeatability, Intraclass Correlation Coefficient, and Measurement Error in R and SAS.” Computing Bird. Liljequist, David, Britt Elfving, and Kirsti Skavberg Roaldsen. 2019. “Intraclass Correlation – A Discussion and Demonstration of Basic Features.” PLoS ONE 14 (7): e0219854. https://doi.org/10.1371/journal.pone.0219854. Ten Hove, Debby, Terrence D. Jorgensen, and L. Andries Van Der Ark. 2024. “Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.” Psychological Methods 29 (5): 967–79. https://doi.org/10.1037/met0000516. Vispoel, Walter P., Carrie A. Morris, and Murat Kilinc. 2018. “Applications of Generalizability Theory and Their Relations to Classical Test Theory and Structural Equation Modeling.” Psychological Methods 23 (1): 1–26. https://doi.org/10.1037/met0000107. "],["supervised-learning.html", "Supervised learning 3.10 Decision trees (also known as classification and regression trees [CART], conditional inference trees)", " Supervised learning 3.10 Decision trees (also known as classification and regression trees [CART], conditional inference trees) 3.10.1 General explanations and interpretation Start with this paper and focus on the CART (Classification and Regression Tree) section mainly. A plainer-language explanation of how splits are chosen with a sample dataset on irises and some exerpts from ctree documentation. 3.10.2 Examples of CART in the wild These two papers use R’s ctree() from the partykit package Available through OU’s subscriptions Available via Interlibrary Loan Access OU’s Interlibrary Loan Article Request Form A different algorithm to run CART: I suggest it because it has good figures and methods section 3.10.3 How and why to run the ctree version of CART/decision trees A short explanation of why ctree is a good general choice to minimize overfitting. The R vignette for the partykit package provides worked examples and code for both categorical responses (classification trees) and numeric responses (regression trees). ggparty allows for fancier and more informative plots Another example using ggparty with a published dataset "],["what-each-section-has.html", "What each section has 3.11 Explanation 3.12 Examples “in the wild”", " What each section has 3.11 Explanation 3.11.1 The basics A simple explanation and hopefully figure of what the test does or gets at. 3.11.2 More technical 3.11.2.1 Questions and data types Example problem structures and types of data you need. 3.11.2.2 Key assumptions This is how to know if you can use the method. 3.11.2.3 Key distinctions among related methods Within and among methods - related? 3.11.2.4 Implementations and controversies 3.11.3 Most technical The key citations. 3.12 Examples “in the wild” Citations and what is useful in the paper. Curry, Claire M. 2016. “Repeatability, Intraclass Correlation Coefficient, and Measurement Error in R and SAS.” Computing Bird. Liljequist, David, Britt Elfving, and Kirsti Skavberg Roaldsen. 2019. “Intraclass Correlation – A Discussion and Demonstration of Basic Features.” PLoS ONE 14 (7): e0219854. https://doi.org/10.1371/journal.pone.0219854. Ten Hove, Debby, Terrence D. Jorgensen, and L. Andries Van Der Ark. 2024. “Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.” Psychological Methods 29 (5): 967–79. https://doi.org/10.1037/met0000516. Vispoel, Walter P., Carrie A. Morris, and Murat Kilinc. 2018. “Applications of Generalizability Theory and Their Relations to Classical Test Theory and Structural Equation Modeling.” Psychological Methods 23 (1): 1–26. https://doi.org/10.1037/met0000107. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
