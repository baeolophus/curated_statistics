[["index.html", "Curated Statistics Who is this book for?", " Curated Statistics C.M. Curry 2025-07-25 Who is this book for? "],["what-is-your-goal.html", "Chapter 1 What is your goal? 1.1 Exploratory or hypothesis generation 1.2 Inferential or hypothesis testing “Are things different” 1.3 Physical or mechanistic predictions - you can only statistics them away sometimes", " Chapter 1 What is your goal? 1.1 Exploratory or hypothesis generation 1.2 Inferential or hypothesis testing “Are things different” This is a hypothesis, not a description. Description can highlight, but doesn’t test what’s different. Descriptions can still have a bias (mean vs median vs range all show different things descriptively, PCA problems). Doesn’t mean it’s an experiment. summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 1.3 Physical or mechanistic predictions - you can only statistics them away sometimes You can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot. "],["types-of-resources.html", "Chapter 2 Types of resources", " Chapter 2 Types of resources Peer-reviewed vs not: what can you cite? What helps? "],["references.html", "References", " References "],["distributions.html", "Chapter 3 Distributions 3.1 Bounded 3.2 Heteroscedascitity vs homoscedasicity 3.3 Theoretical, existing, known 3.4 Simulated, randomized, computational 3.5 When to use either?", " Chapter 3 Distributions The underlying distribution of the variables in your sample population makes a big difference in what inferential statistics you can use. Different methods assume (or don’t) different distributions. If you violate assumptions, sometimes the statistical tests or estimates from the methods may not be valid. 3.1 Bounded 3.2 Heteroscedascitity vs homoscedasicity 3.3 Theoretical, existing, known 3.4 Simulated, randomized, computational 3.5 When to use either? It seems like objections to bootstrapping linear models (and presumably other complex models) fall into two categories: 1. Sampling design isn’t accounted for by complete randomization (ignoring stratification of categories or other sampling vagaries) 2. It’s less elegant (???). Venables and Ripley 2002, pg 164, say “we see bootstrapping as having little place in least-squares regression. If the errors are close to normal, the standard theory suffices. If not, there are better methods of fitting than least squares, or perhaps the data should be transformed […]” Hastie et al. 2008 (Elements of Statistical Learning) seem in favor of bootstrapping (johnston_bootstrap_2021?) are enthusiastically in favor of the bootstrap at least for their relatively simple design to replace a t-test. - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8613103/#CR47 – says do all the other stuff like deal with random effects and autocorrelation first. We have done this already. Example: should we run a Redundancy Analysis (RDA) a la https://r.qcbs.ca/workshop10/book-en/redundancy-analysis.html , which I understand has multivariate normality assumptions. He has a small sample size (around 35 I believe) and residuals are not coming out normal in smaller linear models. - https://journals.sagepub.com/doi/10.1177/0049124189018002003 - https://statisticsbyjim.com/hypothesis-testing/bootstrapping/ - https://online.stat.psu.edu/stat555/node/119/ - https://www.sagepub.com/sites/default/files/upm-binaries/21122_Chapter_21.pdf - https://link.springer.com/referenceworkentry/10.1007/978-1-4419-1153-7_84 "],["how-to-use-this-section.html", "How to use this section", " How to use this section Each section will contain some potential descriptions if needed OR direct citations and links to relevant literature if those explanations are clearest. "],["explaining-odds-ratios.html", "Explaining Odds Ratios 3.6 Explanation 3.7 Examples “in the wild”", " Explaining Odds Ratios 3.6 Explanation 3.6.1 The basics In some regression models (examples here are logistic and Poisson regression), instead of a beta coefficient that can be interpreted as-is, you are given log odds (DWin 2011). Those must be converted to odds ratios, or their Poisson similar cousin relative risk/relative odds. You can present both the original log odds estimate plus the odds ratio / relative risk in your results table. Basic explanation (“FAQ: How Do I Interpret Odds Ratios in Logistic Regression?” n.d.) for logistic regression that walks from probabilities to odds to log odds to dds ratios. has examples for a variety of types of predictor variables. Additionally: Slides 20-24: https://clas.ucdenver.edu/marcelo-perraillon/content/marginal-effects-lisbon “FAQ: How Do I Interpret Odds Ratios in Logistic Regression?” n.d. Accessed May 20, 2022. https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/. Section 6.1: https://clas.ucdenver.edu/marcelo-perraillon/sites/default/files/attached-files/plh_chapter_6_marginal_effects_jan_2023.pdf 3.6.2 More technical 3.6.2.1 Questions and data types Example problem structures and types of data you need. The whole analysis page (“Poisson Regression | R Data Analysis Examples” n.d.), specifically look at the secion called “Poisson regression” about halfway down the page and the second bullet point for interpreting coefficients specifically. The whole analysis page (“Logit Regression | R Data Analysis Examples” n.d.), section where it will talk about coefficients. (Hector 2015) has a good walkthrough of conversion on pp 130-134 for binary/logistic and 137-138 for Poisson data. Box 13.2 in Quinn and Keough also has a good work-through (logistic regression, but as long as both use the default log link the interpretation is similar). 3.6.2.2 Key assumptions Did you run a GLM with a log link or logit link? Then yes. 3.6.2.3 Key distinctions among related methods Odds ratio for logistic vs relative risk for Poisson (DWin 2011). There is a good summary chapter about odds ratios vs log odds vs other related confusing terms. 3.6.2.4 Implementations and controversies Very helpful to plot your data (Cameron 2021) so you are interpreting in the correct direction, as for any type of regression. 3.6.3 Most technical The key citations. 3.7 Examples “in the wild” Citations and what is useful in the paper. References Cameron, Allan. 2021. “Answer to \"How Can I Create a Ggplot with a Regression Line Based on the Predicted Values of a Glm?\".” Stack Overflow. November 2, 2021. https://stackoverflow.com/a/69811892. DWin. 2011. “Answer to \"How to Interpret Coefficients in a Poisson Regression?\".” Cross Validated. May 21, 2011. https://stats.stackexchange.com/a/11097. “FAQ: How Do I Interpret Odds Ratios in Logistic Regression?” n.d. Accessed May 20, 2022. https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/. Hector, Andy. 2015. “9: Generalized Linear Models for Data with Non-Normal Distributions.” In New Statistics with R: An Introduction for Biologists, 1st ed., 121–40. Oxford (GB): Oxford university press. “Logit Regression | R Data Analysis Examples.” n.d. Accessed May 20, 2022. https://stats.oarc.ucla.edu/r/dae/logit-regression/. “Poisson Regression | R Data Analysis Examples.” n.d. Accessed July 25, 2025. https://stats.oarc.ucla.edu/r/dae/poisson-regression/. "],["principal-components-analysis.html", "Principal components analysis 3.8 Explanation. 3.9 email text", " Principal components analysis 3.8 Explanation. Cite Allison Horst’s whale figure here. 3.8.1 Questions and data types 3.8.2 Key assumptions 3.8.3 Key distinctions among methods within PCA 3.9 email text 3.9.1 CART/ctree explanations - Start with this one, CART section mainly: [http://www.jstor.org/stable/10.1086/587826](http://www.jstor.org/stable/10.1086/587826) - [https://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees](https://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees) - [https://stats.stackexchange.com/questions/255150/how-to-interpret-this-decision-tree](https://stats.stackexchange.com/questions/255150/how-to-interpret-this-decision-tree) 3.9.2 Examples of PCA in the wild: - [https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/1051-0761%282006%29016%5B0687%3AHELMAR%5D2.0.CO%3B2](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/1051-0761%282006%29016%5B0687%3AHELMAR%5D2.0.CO%3B2) - Uses R’s ctree: [https://link.springer.com/article/10.1007/s11252-019-00896-0](https://link.springer.com/article/10.1007/s11252-019-00896-0) 3.9.3 Once you have decided to use it, check implementation "],["intraclass-correlation-coefficient-a.k.a.-repeatability.html", "Intraclass Correlation Coefficient a.k.a. repeatability 3.10 Explanation 3.11 Examples “in the wild”", " Intraclass Correlation Coefficient a.k.a. repeatability 3.10 Explanation 3.10.1 The basics Repeatability, as measured by the intraclass correlation coefficient (ICC), is a unitless way to see if measurements are consistent. If you measure the same thing more than once, are you going to get a similar answer? This is usually calculated by comparing (in some way, methods vary) how much variation there is within a given object/individual measured versus the variation over all measurements of all individuals. Here’s an example using SAS sample data (“PROC NESTED: Variability of Calcium Concentration in Turnip Greens :: SAS/STAT(R) 9.2 User’s Guide, Second Edition” n.d.). # title &#39;Calcium Concentration in Turnip Leaves&#39; # &#39;--Nested Random Model&#39;; # title2 &#39;Snedecor and Cochran, &#39;&#39;Statistical Methods&#39;&#39;&#39; # &#39;, 1976, p. 286&#39;; # data Turnip; # do Plant=1 to 4; # do Leaf=1 to 3; # do Sample=1 to 2; # input Calcium @@; # output; # end; # end; # end; # datalines; # 3.28 3.09 3.52 3.48 2.88 2.80 2.46 2.44 # 1.87 1.92 2.19 2.19 2.77 2.66 3.74 3.44 # 2.55 2.55 3.78 3.87 4.07 4.12 3.31 3.31 # ; # # proc nested data=Turnip; # classes plant leaf; # var calcium; # run; Plant &lt;- 1:4 Leaf &lt;- 1:3 Sample = 1:2 turnip &lt;- expand.grid(Sample=Sample, Leaf=Leaf, Plant=Plant) turnip$calcium &lt;- c(3.28, 3.09, 3.52, 3.48, 2.88, 2.80, 2.46, 2.44, 1.87, 1.92, 2.19, 2.19, 2.77, 2.66, 3.74, 3.44, 2.55, 2.55, 3.78, 3.87, 4.07, 4.12, 3.31, 3.31) library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version 4.4.3 ggplot(data = turnip, mapping = aes(x = Plant, y = calcium, color = as.factor(Leaf), shape = as.factor(Sample))) + geom_point() 3.10.2 More technical 3.10.2.1 Questions and data types Example problem structures and types of data you need. 3.10.2.2 Key assumptions and limitations 3.10.2.2.1 Assumptions This is how to know if you can use the method. Most assume Gaussian/normal data, but Nakagawa and Schielzeth (2010) extend to non-normal data. 3.10.2.2.2 Limitations It’s important to pick the right ICC calculation for your study design, though at least one paper says you can do all three (Liljequist, Elfving, and Skavberg Roaldsen 2019) and compare. Bailey and Byrnes (1990) suggest how to calculate a suitable sample size for studies based on the measurement error found. Two thresholds are listed on the wikipedia page (“Intraclass Correlation” 2024), but neither paper provides justifications for their thresholds. (One study (Koo and Li 2016) has an erratum due to a key equation being incorrect in the feature comparison table (“Erratum to ‘A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research’ [J Chiropr Med 2016;15(2):155-163]” 2017).) More realistically, you need to know what it actually means for your data and concepts being test (Wilson 2018). There’s nothing magic about any particular threshold. 3.10.2.3 Key distinctions among related methods “Generalizability theory” (“G-Theory”) is related to “classic test theory” which appears to contain repeatability and ICCs (Vispoel, Morris, and Kilinc 2018).This seems to provide a broader range of indices of how reliable measurements are, but may not be necessary for simple applications. 3.10.2.4 Implementation and controversies 3.10.2.4.1 Choosing your ICC calculation (Liljequist, Elfving, and Skavberg Roaldsen 2019) claim it doesn’t matter which ICC method you use, and that if you use all three main methods you can use any differences to suggest what type of bias you may have in measurements. Lots of papers summarize how to use it (in Zotero library, working to figure out which ones best.) Most recent one (Ten Hove, Jorgensen, and Van Der Ark 2024) isn’t in ResearchRabbit.ai to easy visualize which papers cite the same papers. I have submitted a help request to them and a record change to OA for OpenAlex.org (which showed it as closed). (Curry 2016) describe how to implement in R and SAS. 3.10.3 Most technical The key citations. 3.11 Examples “in the wild” Citations and what is useful in the paper. The most updated guideline is (Ten Hove, Jorgensen, and Van Der Ark 2024) References Bailey, Robert C., and Janice Byrnes. 1990. “A New, Old Method for Assessing Measurement Error in Both Univariate and Multivariate Morphometric Studies.” Systematic Biology 39 (2): 124–30. https://doi.org/10.2307/2992450. Curry, Claire M. 2016. “Repeatability, Intraclass Correlation Coefficient, and Measurement Error in R and SAS.” Computing Bird. January 26, 2016. http://www.cmcurry.com/2016/01/repeatability-intraclass-correlation.html. “Erratum to ‘A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research’ [J Chiropr Med 2016;15(2):155-163].” 2017. Journal of Chiropractic Medicine 16 (4): 346. https://doi.org/10.1016/j.jcm.2017.10.001. “Intraclass Correlation.” 2024. In Wikipedia. https://en.wikipedia.org/w/index.php?title=Intraclass_correlation&amp;oldid=1250304616. Koo, Terry K., and Mae Y. Li. 2016. “A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.” Journal of Chiropractic Medicine 15 (2): 155–63. https://doi.org/10.1016/j.jcm.2016.02.012. Liljequist, David, Britt Elfving, and Kirsti Skavberg Roaldsen. 2019. “Intraclass Correlation – A Discussion and Demonstration of Basic Features.” PLoS ONE 14 (7): e0219854. https://doi.org/10.1371/journal.pone.0219854. Nakagawa, Shinichi, and Holger Schielzeth. 2010. “Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.” Biological Reviews of the Cambridge Philosophical Society 85 (4): 935–56. https://doi.org/10.1111/j.1469-185X.2010.00141.x. “PROC NESTED: Variability of Calcium Concentration in Turnip Greens :: SAS/STAT(R) 9.2 User’s Guide, Second Edition.” n.d. Accessed February 3, 2025. https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_nested_sect020.htm. Ten Hove, Debby, Terrence D. Jorgensen, and L. Andries Van Der Ark. 2024. “Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.” Psychological Methods 29 (5): 967–79. https://doi.org/10.1037/met0000516. Vispoel, Walter P., Carrie A. Morris, and Murat Kilinc. 2018. “Applications of Generalizability Theory and Their Relations to Classical Test Theory and Structural Equation Modeling.” Psychological Methods 23 (1): 1–26. https://doi.org/10.1037/met0000107. Wilson, Alastair J. 2018. “How Should We Interpret Estimates of Individual Repeatability?” Evolution Letters 2 (1): 4–8. https://doi.org/10.1002/evl3.40. "],["supervised-learning.html", "Supervised learning 3.12 Decision trees (also known as classification and regression trees [CART], conditional inference trees)", " Supervised learning 3.12 Decision trees (also known as classification and regression trees [CART], conditional inference trees) 3.12.1 General explanations and interpretation Start with this paper and focus on the CART (Classification and Regression Tree) section mainly. A plainer-language explanation of how splits are chosen with a sample dataset on irises and some exerpts from ctree documentation. 3.12.2 Examples of CART in the wild These two papers use R’s ctree() from the partykit package Available through OU’s subscriptions Available via Interlibrary Loan Access OU’s Interlibrary Loan Article Request Form A different algorithm to run CART: I suggest it because it has good figures and methods section 3.12.3 How and why to run the ctree version of CART/decision trees A short explanation of why ctree is a good general choice to minimize overfitting. The R vignette for the partykit package provides worked examples and code for both categorical responses (classification trees) and numeric responses (regression trees). ggparty allows for fancier and more informative plots Another example using ggparty with a published dataset "],["what-each-section-has.html", "What each section has 3.13 Explanation 3.14 Examples “in the wild”", " What each section has 3.13 Explanation 3.13.1 The basics A simple explanation and hopefully figure of what the test does or gets at. 3.13.2 More technical 3.13.2.1 Questions and data types Example problem structures and types of data you need. 3.13.2.2 Key assumptions This is how to know if you can use the method. 3.13.2.3 Key distinctions among related methods Within and among methods - related? 3.13.2.4 Implementations and controversies 3.13.3 Most technical The key citations. 3.14 Examples “in the wild” Citations and what is useful in the paper. Bailey, Robert C., and Janice Byrnes. 1990. “A New, Old Method for Assessing Measurement Error in Both Univariate and Multivariate Morphometric Studies.” Systematic Biology 39 (2): 124–30. https://doi.org/10.2307/2992450. Cameron, Allan. 2021. “Answer to \"How Can I Create a Ggplot with a Regression Line Based on the Predicted Values of a Glm?\".” Stack Overflow. November 2, 2021. https://stackoverflow.com/a/69811892. Curry, Claire M. 2016. “Repeatability, Intraclass Correlation Coefficient, and Measurement Error in R and SAS.” Computing Bird. January 26, 2016. http://www.cmcurry.com/2016/01/repeatability-intraclass-correlation.html. DWin. 2011. “Answer to \"How to Interpret Coefficients in a Poisson Regression?\".” Cross Validated. May 21, 2011. https://stats.stackexchange.com/a/11097. “Erratum to ‘A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research’ [J Chiropr Med 2016;15(2):155-163].” 2017. Journal of Chiropractic Medicine 16 (4): 346. https://doi.org/10.1016/j.jcm.2017.10.001. “FAQ: How Do I Interpret Odds Ratios in Logistic Regression?” n.d. Accessed May 20, 2022. https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/. Hector, Andy. 2015. “9: Generalized Linear Models for Data with Non-Normal Distributions.” In New Statistics with R: An Introduction for Biologists, 1st ed., 121–40. Oxford (GB): Oxford university press. “Intraclass Correlation.” 2024. In Wikipedia. https://en.wikipedia.org/w/index.php?title=Intraclass_correlation&amp;oldid=1250304616. Koo, Terry K., and Mae Y. Li. 2016. “A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.” Journal of Chiropractic Medicine 15 (2): 155–63. https://doi.org/10.1016/j.jcm.2016.02.012. Liljequist, David, Britt Elfving, and Kirsti Skavberg Roaldsen. 2019. “Intraclass Correlation – A Discussion and Demonstration of Basic Features.” PLoS ONE 14 (7): e0219854. https://doi.org/10.1371/journal.pone.0219854. “Logit Regression | R Data Analysis Examples.” n.d. Accessed May 20, 2022. https://stats.oarc.ucla.edu/r/dae/logit-regression/. Nakagawa, Shinichi, and Holger Schielzeth. 2010. “Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.” Biological Reviews of the Cambridge Philosophical Society 85 (4): 935–56. https://doi.org/10.1111/j.1469-185X.2010.00141.x. “Poisson Regression | R Data Analysis Examples.” n.d. Accessed July 25, 2025. https://stats.oarc.ucla.edu/r/dae/poisson-regression/. “PROC NESTED: Variability of Calcium Concentration in Turnip Greens :: SAS/STAT(R) 9.2 User’s Guide, Second Edition.” n.d. Accessed February 3, 2025. https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_nested_sect020.htm. Ten Hove, Debby, Terrence D. Jorgensen, and L. Andries Van Der Ark. 2024. “Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.” Psychological Methods 29 (5): 967–79. https://doi.org/10.1037/met0000516. Vispoel, Walter P., Carrie A. Morris, and Murat Kilinc. 2018. “Applications of Generalizability Theory and Their Relations to Classical Test Theory and Structural Equation Modeling.” Psychological Methods 23 (1): 1–26. https://doi.org/10.1037/met0000107. Wilson, Alastair J. 2018. “How Should We Interpret Estimates of Individual Repeatability?” Evolution Letters 2 (1): 4–8. https://doi.org/10.1002/evl3.40. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
