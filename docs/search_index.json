[["index.html", "Statistics for Scared People Who is this book for?", " Statistics for Scared People C.M. Curry 2025-02-03 Who is this book for? "],["what-is-your-goal.html", "Chapter 1 What is your goal? 1.1 Exploratory or hypothesis generation 1.2 Inferential or hypothesis testing “Are things different” 1.3 Physical or mechanistic predictions - you can only statistics them away sometimes", " Chapter 1 What is your goal? 1.1 Exploratory or hypothesis generation 1.2 Inferential or hypothesis testing “Are things different” This is a hypothesis, not a description. Description can highlight, but doesn’t test what’s different. Descriptions can still have a bias (mean vs median vs range all show different things descriptively, PCA problems). Doesn’t mean it’s an experiment. summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 1.3 Physical or mechanistic predictions - you can only statistics them away sometimes You can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot. "],["types-of-resources.html", "Chapter 2 Types of resources", " Chapter 2 Types of resources Peer-reviewed vs not: what can you cite? What helps? "],["references.html", "References", " References "],["distributions.html", "Chapter 3 Distributions 3.1 Bounded 3.2 Heteroscedascitity vs homoscedasicity 3.3 Theoretical, existing, known 3.4 Simulated, randomized, computational 3.5 When to use either?", " Chapter 3 Distributions The underlying distribution of the variables in your sample population makes a big difference in what inferential statistics you can use. Different methods assume (or don’t) different distributions. If you violate assumptions, sometimes the statistical tests or estimates from the methods may not be valid. 3.1 Bounded 3.2 Heteroscedascitity vs homoscedasicity 3.3 Theoretical, existing, known 3.4 Simulated, randomized, computational 3.5 When to use either? It seems like objections to bootstrapping linear models (and presumably other complex models) fall into two categories: 1. Sampling design isn’t accounted for by complete randomization (ignoring stratification of categories or other sampling vagaries) 2. It’s less elegant (???). Venables and Ripley 2002, pg 164, say “we see bootstrapping as having little place in least-squares regression. If the errors are close to normal, the standard theory suffices. If not, there are better methods of fitting than least squares, or perhaps the data should be transformed […]” Hastie et al. 2008 (Elements of Statistical Learning) seem in favor of bootstrapping (johnston_bootstrap_2021?) are enthusiastically in favor of the bootstrap at least for their relatively simple design to replace a t-test. - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8613103/#CR47 – says do all the other stuff like deal with random effects and autocorrelation first. We have done this already. Example: should we run a Redundancy Analysis (RDA) a la https://r.qcbs.ca/workshop10/book-en/redundancy-analysis.html , which I understand has multivariate normality assumptions. He has a small sample size (around 35 I believe) and residuals are not coming out normal in smaller linear models. - https://journals.sagepub.com/doi/10.1177/0049124189018002003 - https://statisticsbyjim.com/hypothesis-testing/bootstrapping/ - https://online.stat.psu.edu/stat555/node/119/ - https://www.sagepub.com/sites/default/files/upm-binaries/21122_Chapter_21.pdf - https://link.springer.com/referenceworkentry/10.1007/978-1-4419-1153-7_84 "],["how-to-use-this-section.html", "How to use this section", " How to use this section Each section will contain some potential descriptions if needed OR direct citations and links to relevant literature if those explanations are clearest. "],["principal-components-analysis.html", "Principal components analysis 3.6 Explanation. 3.7 email text", " Principal components analysis 3.6 Explanation. Cite Allison Horst’s whale figure here. 3.6.1 Questions and data types 3.6.2 Key assumptions 3.6.3 Key distinctions among methods within PCA 3.7 email text 3.7.1 CART/ctree explanations - Start with this one, CART section mainly: [http://www.jstor.org/stable/10.1086/587826](http://www.jstor.org/stable/10.1086/587826) - [https://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees](https://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees) - [https://stats.stackexchange.com/questions/255150/how-to-interpret-this-decision-tree](https://stats.stackexchange.com/questions/255150/how-to-interpret-this-decision-tree) 3.7.2 Examples of PCA in the wild: - [https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/1051-0761%282006%29016%5B0687%3AHELMAR%5D2.0.CO%3B2](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/1051-0761%282006%29016%5B0687%3AHELMAR%5D2.0.CO%3B2) - Uses R’s ctree: [https://link.springer.com/article/10.1007/s11252-019-00896-0](https://link.springer.com/article/10.1007/s11252-019-00896-0) 3.7.3 Once you have decided to use it, check implementation "],["intraclass-correlation-coefficient-a.k.a.-repeatability.html", "Intraclass Correlation Coefficient a.k.a. repeatability 3.8 Explanation 3.9 Examples “in the wild”", " Intraclass Correlation Coefficient a.k.a. repeatability 3.8 Explanation 3.8.1 The basics Repeatability, as measured by the intraclass correlation coefficient (ICC), is a unitless way to see if measurements are consistent. If you measure the same thing more than once, are you going to get a similar answer? This is usually calculated by comparing (in some way, methods vary) how much variation there is within a given object/individual measured versus the variation over all measurements of all individuals. Here’s an example using SAS sample data (“PROC NESTED: Variability of Calcium Concentration in Turnip Greens :: SAS/STAT(R) 9.2 User’s Guide, Second Edition” n.d.). # title &#39;Calcium Concentration in Turnip Leaves&#39; # &#39;--Nested Random Model&#39;; # title2 &#39;Snedecor and Cochran, &#39;&#39;Statistical Methods&#39;&#39;&#39; # &#39;, 1976, p. 286&#39;; # data Turnip; # do Plant=1 to 4; # do Leaf=1 to 3; # do Sample=1 to 2; # input Calcium @@; # output; # end; # end; # end; # datalines; # 3.28 3.09 3.52 3.48 2.88 2.80 2.46 2.44 # 1.87 1.92 2.19 2.19 2.77 2.66 3.74 3.44 # 2.55 2.55 3.78 3.87 4.07 4.12 3.31 3.31 # ; # # proc nested data=Turnip; # classes plant leaf; # var calcium; # run; Plant &lt;- 1:4 Leaf &lt;- 1:3 Sample = 1:2 turnip &lt;- expand.grid(Sample=Sample, Leaf=Leaf, Plant=Plant) turnip$calcium &lt;- c(3.28, 3.09, 3.52, 3.48, 2.88, 2.80, 2.46, 2.44, 1.87, 1.92, 2.19, 2.19, 2.77, 2.66, 3.74, 3.44, 2.55, 2.55, 3.78, 3.87, 4.07, 4.12, 3.31, 3.31) library(ggplot2) ggplot(data = turnip, mapping = aes(x = Plant, y = calcium, color = as.factor(Leaf), shape = as.factor(Sample))) + geom_point() 3.8.2 More technical 3.8.2.1 Questions and data types Example problem structures and types of data you need. 3.8.2.2 Key assumptions and limitations 3.8.2.2.1 Assumptions This is how to know if you can use the method. Most assume Gaussian/normal data, but Nakagawa and Schielzeth (2010) extend to non-normal data. 3.8.2.2.2 Limitations It’s important to pick the right ICC calculation for your study design, though at least one paper says you can do all three (Liljequist, Elfving, and Skavberg Roaldsen 2019) and compare. Bailey and Byrnes (1990) suggest how to calculate a suitable sample size for studies based on the measurement error found. Two thresholds are listed on the wikipedia page (“Intraclass Correlation” 2024), but neither paper provides justifications for their thresholds. (One study (Koo and Li 2016) has an erratum due to a key equation being incorrect in the feature comparison table (“Erratum to ‘A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research’ [J Chiropr Med 2016;15(2):155-163]” 2017).) More realistically, you need to know what it actually means for your data and concepts being test (Wilson 2018). There’s nothing magic about any particular threshold. 3.8.2.3 Key distinctions among related methods “Generalizability theory” (“G-Theory”) is related to “classic test theory” which appears to contain repeatability and ICCs (Vispoel, Morris, and Kilinc 2018).This seems to provide a broader range of indices of how reliable measurements are, but may not be necessary for simple applications. 3.8.2.4 Implementation and controversies 3.8.2.4.1 Choosing your ICC calculation (Liljequist, Elfving, and Skavberg Roaldsen 2019) claim it doesn’t matter which ICC method you use, and that if you use all three main methods you can use any differences to suggest what type of bias you may have in measurements. Lots of papers summarize how to use it (in Zotero library, working to figure out which ones best.) Most recent one (Ten Hove, Jorgensen, and Van Der Ark 2024) isn’t in ResearchRabbit.ai to easy visualize which papers cite the same papers. I have submitted a help request to them and a record change to OA for OpenAlex.org (which showed it as closed). (Curry 2016) describe how to implement in R and SAS. 3.8.3 Most technical The key citations. 3.9 Examples “in the wild” Citations and what is useful in the paper. The most updated guideline is (Ten Hove, Jorgensen, and Van Der Ark 2024) References Bailey, Robert C., and Janice Byrnes. 1990. “A New, Old Method for Assessing Measurement Error in Both Univariate and Multivariate Morphometric Studies.” Systematic Biology 39 (2): 124–30. https://doi.org/10.2307/2992450. Curry, Claire M. 2016. “Repeatability, Intraclass Correlation Coefficient, and Measurement Error in R and SAS.” Computing Bird. http://www.cmcurry.com/2016/01/repeatability-intraclass-correlation.html. “Erratum to ‘A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research’ [J Chiropr Med 2016;15(2):155-163].” 2017. Journal of Chiropractic Medicine 16 (4): 346. https://doi.org/10.1016/j.jcm.2017.10.001. “Intraclass Correlation.” 2024. Wikipedia, October. Koo, Terry K., and Mae Y. Li. 2016. “A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.” Journal of Chiropractic Medicine 15 (2): 155–63. https://doi.org/10.1016/j.jcm.2016.02.012. Liljequist, David, Britt Elfving, and Kirsti Skavberg Roaldsen. 2019. “Intraclass Correlation – A Discussion and Demonstration of Basic Features.” PLoS ONE 14 (7): e0219854. https://doi.org/10.1371/journal.pone.0219854. Nakagawa, Shinichi, and Holger Schielzeth. 2010. “Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.” Biological Reviews of the Cambridge Philosophical Society 85 (4): 935–56. https://doi.org/10.1111/j.1469-185X.2010.00141.x. “PROC NESTED: Variability of Calcium Concentration in Turnip Greens :: SAS/STAT(R) 9.2 User’s Guide, Second Edition.” n.d. https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_nested_sect020.htm. Accessed February 3, 2025. Ten Hove, Debby, Terrence D. Jorgensen, and L. Andries Van Der Ark. 2024. “Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.” Psychological Methods 29 (5): 967–79. https://doi.org/10.1037/met0000516. Vispoel, Walter P., Carrie A. Morris, and Murat Kilinc. 2018. “Applications of Generalizability Theory and Their Relations to Classical Test Theory and Structural Equation Modeling.” Psychological Methods 23 (1): 1–26. https://doi.org/10.1037/met0000107. Wilson, Alastair J. 2018. “How Should We Interpret Estimates of Individual Repeatability?” Evolution Letters 2 (1): 4–8. https://doi.org/10.1002/evl3.40. "],["supervised-learning.html", "Supervised learning 3.10 Decision trees (also known as classification and regression trees [CART], conditional inference trees)", " Supervised learning 3.10 Decision trees (also known as classification and regression trees [CART], conditional inference trees) 3.10.1 General explanations and interpretation Start with this paper and focus on the CART (Classification and Regression Tree) section mainly. A plainer-language explanation of how splits are chosen with a sample dataset on irises and some exerpts from ctree documentation. 3.10.2 Examples of CART in the wild These two papers use R’s ctree() from the partykit package Available through OU’s subscriptions Available via Interlibrary Loan Access OU’s Interlibrary Loan Article Request Form A different algorithm to run CART: I suggest it because it has good figures and methods section 3.10.3 How and why to run the ctree version of CART/decision trees A short explanation of why ctree is a good general choice to minimize overfitting. The R vignette for the partykit package provides worked examples and code for both categorical responses (classification trees) and numeric responses (regression trees). ggparty allows for fancier and more informative plots Another example using ggparty with a published dataset "],["what-each-section-has.html", "What each section has 3.11 Explanation 3.12 Examples “in the wild”", " What each section has 3.11 Explanation 3.11.1 The basics A simple explanation and hopefully figure of what the test does or gets at. 3.11.2 More technical 3.11.2.1 Questions and data types Example problem structures and types of data you need. 3.11.2.2 Key assumptions This is how to know if you can use the method. 3.11.2.3 Key distinctions among related methods Within and among methods - related? 3.11.2.4 Implementations and controversies 3.11.3 Most technical The key citations. 3.12 Examples “in the wild” Citations and what is useful in the paper. Bailey, Robert C., and Janice Byrnes. 1990. “A New, Old Method for Assessing Measurement Error in Both Univariate and Multivariate Morphometric Studies.” Systematic Biology 39 (2): 124–30. https://doi.org/10.2307/2992450. Curry, Claire M. 2016. “Repeatability, Intraclass Correlation Coefficient, and Measurement Error in R and SAS.” Computing Bird. http://www.cmcurry.com/2016/01/repeatability-intraclass-correlation.html. “Erratum to ‘A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research’ [J Chiropr Med 2016;15(2):155-163].” 2017. Journal of Chiropractic Medicine 16 (4): 346. https://doi.org/10.1016/j.jcm.2017.10.001. “Intraclass Correlation.” 2024. Wikipedia, October. Koo, Terry K., and Mae Y. Li. 2016. “A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.” Journal of Chiropractic Medicine 15 (2): 155–63. https://doi.org/10.1016/j.jcm.2016.02.012. Liljequist, David, Britt Elfving, and Kirsti Skavberg Roaldsen. 2019. “Intraclass Correlation – A Discussion and Demonstration of Basic Features.” PLoS ONE 14 (7): e0219854. https://doi.org/10.1371/journal.pone.0219854. Nakagawa, Shinichi, and Holger Schielzeth. 2010. “Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.” Biological Reviews of the Cambridge Philosophical Society 85 (4): 935–56. https://doi.org/10.1111/j.1469-185X.2010.00141.x. “PROC NESTED: Variability of Calcium Concentration in Turnip Greens :: SAS/STAT(R) 9.2 User’s Guide, Second Edition.” n.d. https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_nested_sect020.htm. Accessed February 3, 2025. Ten Hove, Debby, Terrence D. Jorgensen, and L. Andries Van Der Ark. 2024. “Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.” Psychological Methods 29 (5): 967–79. https://doi.org/10.1037/met0000516. Vispoel, Walter P., Carrie A. Morris, and Murat Kilinc. 2018. “Applications of Generalizability Theory and Their Relations to Classical Test Theory and Structural Equation Modeling.” Psychological Methods 23 (1): 1–26. https://doi.org/10.1037/met0000107. Wilson, Alastair J. 2018. “How Should We Interpret Estimates of Individual Repeatability?” Evolution Letters 2 (1): 4–8. https://doi.org/10.1002/evl3.40. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
